import{aa as d,ab as r}from"./_applist-chatty-months-shout-814.js";import{_ as t}from"./main-chatty-months-shout.js";import{s as u}from"./machine.-chatty-months-shout-207.js";import{a as s}from"./machineh-chatty-months-shout-278.js";import{h as _,b as i,c as h}from"./openaico-chatty-months-shout-481.js";import"./lodash-chatty-months-shout-731.js";globalThis.jotaiAtomCache=globalThis.jotaiAtomCache||{cache:new Map,get(a,e){return this.cache.has(a)?this.cache.get(a):(this.cache.set(a,e),e)}};const T=["reasoning-effort","temperature","top-p","frequency-penalty","presence-penalty"],c=new Set(["o1","o1-2024-12-17","o3-mini","o3-mini-2025-01-31"]),C=new Set(["o1","o1-2024-12-17","o1-mini","o1-mini-2024-09-12","o1-preview","o1-preview-2024-09-12","o4-mini","o4-mini-2025-04-16"]),A=d(({helpers:a})=>({states:{components:[h(a),{componentName:a.componentName.select,id:"model-id",label:t("Select Model"),onChange:"SET_MODEL",onRefetch:"REFETCH_MODEL_LIST",optionFilterProp:"label",options:[],path:"model",placeholder:t("Select a Model"),render:"IF_CONNECTION_SELECTED",required:!0,showSearch:!0,value:""},{componentName:a.componentName.switch,fieldType:"config",id:"show-advance-feature",label:t("Show Advance Feature"),onChange:"SET_FEATURE",render:"IF_MODEL_SELECTED",size:"small",value:!1},{componentName:a.componentName.mixInput,helperText:t("If empty, the limit of the model will be used. Note that: - Low values may cause the output to be truncated. - High values may use a lot of OpenAI credit. When using reasoning models such as the o1 models, this value is the sum of reasoning + output tokens."),id:"max-token",label:t("Max Completion Token"),onChange:"SET_MAX_TOKEN",path:"max_tokens",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.select,helperText:t("Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."),id:"reasoning_effort",label:t("Reasoning Effort"),onChange:"SET_REASONING_EFFECT",options:[{label:t("Low"),value:"low"},{label:t("Medium"),value:"medium"},{label:t("High"),value:"high"}],path:"reasoning_effort",placeholder:t("Select a Effort"),render:"IF_REASONING_MODEL_SELECTED",required:!0,value:void 0},{componentName:a.componentName.mixInput,helperText:t("Higher temperatures generate more diverse and creative responses. For example, 0.8. Lower temperatures generate more focused and well-defined responses. For example, 0.2. The default value is 1. Must be lower than or equal to 2."),id:"temperature",label:t("Temperature"),onChange:"SET_TEMPERATURE",path:"temperature",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:t("Alternative to sampling with temperature, based on token probability. For example, .1 means only the tokens in the top 10% probability mass are considered. The default value is 1. Must be lower than or equal to 1."),id:"top-p",label:t("Top P"),onChange:"SET_TOP_P",path:"top_p",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:t("Number of responses to generate. The results can be found in the modules output in Choices. The default value is 1."),id:"frequency-penalty",label:t("Frequency Penalty"),onChange:"SET_FREQUENCY_PENALTY",path:"frequency_penalty",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:t("Positive values discourage repeated token usage, increasing diversity and the likelihood of new topics. Negative values encourage repeated token usage, reinforcing existing patterns. Must be a number between -2 and 2."),id:"presence-penalty",label:t("Presence Penalty"),onChange:"SET_PRESENCE_PENALTY",path:"presence_penalty",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]}]},actions:{SET_CONNECTION:async({$:e,e:o})=>{e.setThisComponent(n=>{n.value=o}),e.setDb(n=>{n.connectionId=o}),await s(e)},IF_CONNECTION_SELECTED:({$:e})=>{var o;return r((o=e.getComponent("connection-id"))==null?void 0:o.value)},IF_MODEL_SELECTED:({$:e})=>{var o,n;return r((o=e.getComponent("connection-id"))==null?void 0:o.value)&&((n=e.getComponent("model-id"))==null?void 0:n.value)!==""},IF_REASONING_MODEL_SELECTED:({$:e})=>{var E,m,p;const o=(E=e.getComponent("model-id"))==null?void 0:E.value,n=((m=e.getComponent("show-advance-feature"))==null?void 0:m.value)==="true";if(r((p=e.getComponent("connection-id"))==null?void 0:p.value)&&n&&o&&c.has(o))return!0},IF_ADVANCE_FEATURE_SELECTED:({$:e})=>{var o,n;return r((o=e.getComponent("connection-id"))==null?void 0:o.value)&&((n=e.getComponent("show-advance-feature"))==null?void 0:n.value)===!0},REFETCH_MODEL_LIST:async({$:e})=>{await s(e)},SET_MODEL:({$:e,e:o})=>{e.setThisComponent(n=>{n.value=o}),e.setDb(n=>{n.model=o}),c.has(o)&&e.setComponent("reasoning_effort",n=>{e.util.isSelectComponent(n)&&(n.value=void 0)}),C.has(o)&&e.setComponent("max-token",n=>{e.util.isMixInputComponent(n)&&(n.path="max_completion_tokens")})},SET_MAX_TOKEN:i("maxToken"),SET_RESPONSE:i("responseFormat"),SET_REASONING_EFFECT:i("reasoningEffect"),SET_TEMPERATURE:i("temperatureId"),SET_TOP_P:i("topP"),SET_FREQUENCY_PENALTY:i("frequency"),SET_PRESENCE_PENALTY:i("presence"),SET_FEATURE:({$:e,e:o})=>{e.setThisComponent(n=>{n.value=o}),e.setDb(n=>{n.advanceFeature=o}),o===!1&&T.map(n=>e.setComponent(n,l=>{l.value=void 0}))},CONNECTION_ADD_CHANGE:_,ON_MACHINE_LOAD:async({$:e})=>{var o;u(e,[{db:"connectionId",id:"connection-id"},{db:"model",id:"model-id"},{db:"maxToken",id:"max-token"},{db:"advanceFeature",id:"show-advance-feature"},{db:"reasoningEffect",id:"reasoning_effort"},{db:"temperatureId",id:"temperature"},{db:"topP",id:"top-p"},{db:"frequency",id:"frequency-penalty"},{db:"presence",id:"presence-penalty"}]),(o=e.db)!=null&&o.connectionId&&await s(e)}}}));export{A as default};
