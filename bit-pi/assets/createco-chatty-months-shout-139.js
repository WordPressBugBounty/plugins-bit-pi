import{aa as c,ab as s}from"./_applist-chatty-months-shout-814.js";import{_ as e}from"./main-chatty-months-shout.js";import{s as E}from"./machine.-chatty-months-shout-207.js";import{a as m}from"./machineh-chatty-months-shout-278.js";import{h as _,b as l,c as h}from"./openaico-chatty-months-shout-481.js";import"./lodash-chatty-months-shout-731.js";globalThis.jotaiAtomCache=globalThis.jotaiAtomCache||{cache:new Map,get(a,t){return this.cache.has(a)?this.cache.get(a):(this.cache.set(a,t),t)}};e("Alloy"),e("Ash"),e("Ballad"),e("Coral"),e("Echo"),e("Fable"),e("Onyx"),e("Nova"),e("Sage"),e("Shimmer"),e("Verse");e("MP3"),e("Opus"),e("AAC"),e("FLAC"),e("WAV"),e("PCM");const T=[{label:e("User"),value:"user"},{label:e("Assistant"),value:"assistant"},{label:e("Developer/System"),value:"developer"}],b=[{label:e("logit_bias"),value:"logit_bias"},{label:e("logprobs"),value:"logprobs"},{label:e("metadata"),value:"metadata"},{label:e("modalities"),value:"modalities"},{label:e("parallel_tool_calls"),value:"parallel_tool_calls"},{label:e("prediction"),value:"prediction"},{label:e("service_tier"),value:"service_tier"},{label:e("store"),value:"store"},{label:e("stream"),value:"stream"},{label:e("stream_options"),value:"stream_options"},{label:e("tool_choice"),value:"tool_choice"},{label:e("tools"),value:"tools"},{label:e("top_logprobs"),value:"top_logprobs"},{label:e("user"),value:"user"},{label:e("web_search_options"),value:"web_search_options"}];globalThis.jotaiAtomCache=globalThis.jotaiAtomCache||{cache:new Map,get(a,t){return this.cache.has(a)?this.cache.get(a):(this.cache.set(a,t),t)}};const N=["response-format","reasoning-effort","temperature","top-p","number","frequency-penalty","presence-penalty","seed"],I=c(({helpers:a})=>({states:{components:[h(a),{componentName:a.componentName.select,id:"model-id",label:e("Select Model"),onChange:"SET_MODEL",onRefetch:"REFETCH_MODEL_LIST",optionFilterProp:"label",options:[],path:"model",placeholder:e("Select a Model"),render:"IF_CONNECTION_SELECTED",required:!0,showSearch:!0,value:""},{componentName:a.componentName.mixInput,helperText:e("If empty, the limit of the model will be used. Note that: - Low values may cause the output to be truncated. - High values may use a lot of OpenAI credit. When using reasoning models such as the o1 models, this value is the sum of reasoning + output tokens."),id:"max-token",label:e("Max Completion Token"),onChange:"SET_MAX_TOKEN",path:"max_tokens",render:"IF_MODEL_SELECTED",required:!0,value:[]},{componentName:a.componentName.switch,fieldType:"config",helperText:e("Toggle the switch to reveal the Memory Key input field. This crucial setting allows the system to store OpenAI's output responses directly into your database, "),id:"memory-key-switch",label:e("Get Unique Response"),onChange:"SET_UNIQUE_RESPONSE",render:"IF_MODEL_SELECTED",size:"small",value:!1},{componentName:a.componentName.mixInput,fieldType:"config",helperText:e("Enter a unique identifier here (e.g., 'John Doe'). This Memory Key links OpenAI's responses to your specified database entry"),id:"memory-key",label:e("Memory Key"),onChange:"SET_MEMORY_KEY",render:"IF_MEMORY_KEY_SWITCH",required:!0,value:[]},{componentName:a.componentName.mixInput,fieldType:"config",helperText:e("How many recent responses should I remember? (e.g., 5)"),id:"context-length",label:e("Context Length"),onChange:"SET_CONTEXT_LENGTH",render:"IF_MEMORY_KEY_SWITCH",required:!0,value:[]},{addItemButtonLabel:e("Add Message"),componentName:a.componentName.repeaterField,direction:"vertical",fieldsMetaData:[{componentName:a.componentName.select,id:"messages",label:e("Field"),name:"role",options:T,required:!0,value:""},{componentName:a.componentName.mixInput,label:e("Value"),name:"content",required:!0,value:[],wrapperClassName:"w-100"}],id:"messages-list",inputGroupProps:{label:e("Role #{COUNT}")},label:e("Messages"),onChange:"ON_FIELD_MAP_CHANGE",render:"IF_MODEL_SELECTED",value:[]},{componentName:a.componentName.switch,id:"show-advance-feature",label:e("Show Advance Feature"),onChange:"SET_FEATURE",path:"advance-feature",render:"IF_MODEL_SELECTED",size:"small",value:!1},{componentName:a.componentName.select,helperText:e('When using JSON Object, you must also instruct the model to produce JSON via a System or User message. If not, the model can generate an unending stream of whitespace until it reaches the token limit. This will result in a long-running and seemingly "stuck" request.'),id:"response-format",label:e("Response Format"),onChange:"SET_RESPONSE",options:[{label:e("Text"),value:"text"},{label:e("JSON Object"),value:"object"}],path:"response_format",placeholder:e("Select a Format"),render:"IF_ADVANCE_FEATURE_SELECTED",required:!0,value:"text"},{componentName:a.componentName.select,helperText:e("Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response."),id:"reasoning_effort",label:e("Reasoning Effort"),onChange:"SET_REASONING_EFFECT",options:[{label:e("Low"),value:"low"},{label:e("Medium"),value:"medium"},{label:e("High"),value:"high"}],path:"reasoning_effort",placeholder:e("Select a Effort"),render:"IF_REASONING_MODEL_SELECTED",required:!0,value:void 0},{componentName:a.componentName.mixInput,helperText:e("Higher temperatures generate more diverse and creative responses. For example, 0.8. Lower temperatures generate more focused and well-defined responses. For example, 0.2. The default value is 1. Must be lower than or equal to 2."),id:"temperature",label:e("Temperature"),onChange:"SET_TEMPERATURE",path:"temperature",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:e("Alternative to sampling with temperature, based on token probability. For example, .1 means only the tokens in the top 10% probability mass are considered. The default value is 1. Must be lower than or equal to 1."),id:"top-p",label:e("Top P"),onChange:"SET_TOP_P",path:"top_p",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:e("The results can be found in the modules output in Choices. The default value is 1."),id:"number",label:e("Number of responses to generate"),onChange:"SET_NUMBER",path:"n",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:e("Number of responses to generate. The results can be found in the modules output in Choices. The default value is 1."),id:"frequency-penalty",label:e("Frequency Penalty"),onChange:"SET_FREQUENCY_PENALTY",path:"frequency_penalty",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:e("Positive values discourage repeated token usage, increasing diversity and the likelihood of new topics. Negative values encourage repeated token usage, reinforcing existing patterns. Must be a number between -2 and 2."),id:"presence-penalty",label:e("Presence Penalty"),onChange:"SET_PRESENCE_PENALTY",path:"presence_penalty",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{componentName:a.componentName.mixInput,helperText:e("This feature is in Beta. If specified, OpenAI will make a best effort to sample deterministically so that repeated requests with the same seed and parameters return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend."),id:"seed",label:e("Seed"),onChange:"SET_SEED",path:"seed",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{addItemButtonLabel:"Add Stop Sequences",componentName:a.componentName.repeaterField,fieldsMetaData:[{componentName:a.componentName.input,label:e("Stop Sequences"),name:"stop-sequences-id",required:!0,value:void 0}],helperText:e("Maximum of 4 sequences that will trigger OpenAI to stop generating further text. The returned text will not contain the stop sequences."),id:"stop-sequences-list",inputGroupProps:{label:e("Stop Sequences #{COUNT}")},label:e("Stop Sequences"),loading:!1,onChange:"ON_STOP_SEQUENCE_FIELD_MAP_CHANGE",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]},{addItemButtonLabel:e("Add Optional Fields"),componentName:a.componentName.repeaterField,direction:"horizontal",fieldsMetaData:[{componentName:a.componentName.select,id:"optional-fields",label:e("Field"),name:"optional-fields",options:b,required:!0,style:{width:150},value:""},{componentName:a.componentName.mixInput,label:e("Value"),name:"value",required:!0,value:[],wrapperClassName:"w-100"}],id:"optional-field-list",inputGroupProps:{label:e("Field #{COUNT}")},label:e("Optional Fields"),onChange:"ON_OPTIONAL_FIELD_MAP",path:"optionalFields",render:"IF_ADVANCE_FEATURE_SELECTED",value:[]}]},actions:{SET_CONNECTION:async({$:t,e:o})=>{t.setThisComponent(n=>{n.value=o}),t.setDb(n=>{n.connectionId=o}),await m(t)},IF_CONNECTION_SELECTED:({$:t})=>{var o;return s((o=t.getComponent("connection-id"))==null?void 0:o.value)},IF_REASONING_MODEL_SELECTED:({$:t})=>{var u,d,p;const o=(u=t.getComponent("model-id"))==null?void 0:u.value,n=((d=t.getComponent("show-advance-feature"))==null?void 0:d.value)==="true";if(s((p=t.getComponent("connection-id"))==null?void 0:p.value)&&n&&["o3-mini","o3-mini-2025-01-31","o1","o1-2024-12-17"].includes(o))return!0},IF_MODEL_SELECTED:({$:t})=>{var o,n;return s((o=t.getComponent("connection-id"))==null?void 0:o.value)&&((n=t.getComponent("model-id"))==null?void 0:n.value)!==""},IF_MEMORY_KEY_SWITCH:({$:t})=>{var o,n;return s((o=t.getComponent("connection-id"))==null?void 0:o.value)&&((n=t.getComponent("memory-key-switch"))==null?void 0:n.value)===!0},IF_ADVANCE_FEATURE_SELECTED:({$:t})=>{var o,n;return s((o=t.getComponent("connection-id"))==null?void 0:o.value)&&((n=t.getComponent("show-advance-feature"))==null?void 0:n.value)===!0},REFETCH_MODEL_LIST:async({$:t})=>{await m(t)},SET_MODEL:({$:t,e:o})=>{t.setThisComponent(i=>{i.value=o}),t.setDb(i=>{i.model=o});const n=["o3-mini","o3-mini-2025-01-31","o1","o1-2024-12-17"],r=["o1-preview-2024-09-12","o4-mini-2025-04-16","o1-preview","o1-2024-12-17","o1","o1-mini","o4-mini","o1-mini-2024-09-12"];n.includes(o)&&t.setComponent("reasoning_effort",i=>{t.util.isSelectComponent(i)&&(i.value=void 0)}),r.includes(o)&&t.setComponent("max-token",i=>{t.util.isMixInputComponent(i)&&(i.path="max_completion_tokens")})},SET_MAX_TOKEN:l("maxToken"),ON_FIELD_MAP_CHANGE:l("messagesList"),ON_STOP_SEQUENCE_FIELD_MAP_CHANGE:l("stopSequenceList"),ON_OPTIONAL_FIELD_MAP:l("optionalFields"),SET_FEATURE:({$:t,e:o})=>{t.setThisComponent(n=>{n.value=o}),t.setDb(n=>{n.advanceFeature=o}),o===!1&&N.map(n=>t.setComponent(n,r=>{r.value=void 0}))},SET_MEMORY_KEY:l("memoryKey"),SET_CONTEXT_LENGTH:l("contextLength"),SET_RESPONSE:l("responseId"),SET_REASONING_EFFECT:l("reasoningEffect"),SET_TEMPERATURE:l("temperatureId"),SET_TOP_P:l("topP"),SET_NUMBER:l("number"),SET_UNIQUE_RESPONSE:l("memoryKeySwitch"),SET_FREQUENCY_PENALTY:l("frequency"),SET_PRESENCE_PENALTY:l("presence"),SET_SEED:l("seed"),CONNECTION_ADD_CHANGE:_,ON_MACHINE_LOAD:async({$:t})=>{var o;E(t,[{db:"connectionId",id:"connection-id"},{db:"model",id:"model-id"},{db:"maxToken",id:"max-token"},{db:"memoryKey",id:"memory-key"},{db:"messagesList",id:"messages-list"},{db:"advanceFeature",id:"show-advance-feature"},{db:"reasoningEffect",id:"reasoning_effort"},{db:"temperatureId",id:"temperature"},{db:"optionalFields",id:"optional-field-list"},{db:"memoryKeySwitch",id:"memory-key-switch"},{db:"contextLength",id:"context-length"},{db:"number",id:"number"},{db:"topP",id:"top-p"},{db:"frequency",id:"frequency-penalty"},{db:"presence",id:"presence-penalty"},{db:"seed",id:"seed"},{db:"stopSequenceList",id:"stop-sequences-list"}]),(o=t.db)!=null&&o.connectionId&&await m(t)}}}));export{I as default};
